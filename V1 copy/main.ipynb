{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:albumentations.check_version:A new version of Albumentations is available: 2.0.8 (you have 1.4.10). Upgrade using: pip install --upgrade albumentations\n"
     ]
    }
   ],
   "source": [
    "# pip install git+https://github.com/IBM/terratorch.git ##used this code to get latest terratorch download\n",
    "\n",
    "from Decoder_UNet2D import UNet2D\n",
    "from Encoder_TerraMind import TerraMindEncoder\n",
    "from DataLoader import BeforeData\n",
    "from Losses import DiceLoss\n",
    "from utils import RandomCrop\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import os\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y shape, dataloader: torch.Size([1, 457, 447])\n",
      "Y shape: torch.Size([1, 1, 224, 224])\n",
      "logits shape: torch.Size([1, 3, 224, 224])\n",
      "predictions: torch.Size([1, 3, 224, 224])\n",
      "predictions shape: torch.Size([1, 224, 224]) y shape: torch.Size([1, 1, 224, 224])\n",
      "Epoch 1/10 - Loss: -1.1415\n",
      "Y shape, dataloader: torch.Size([1, 457, 447])\n",
      "Y shape: torch.Size([1, 1, 224, 224])\n",
      "logits shape: torch.Size([1, 3, 224, 224])\n",
      "predictions: torch.Size([1, 3, 224, 224])\n",
      "predictions shape: torch.Size([1, 224, 224]) y shape: torch.Size([1, 1, 224, 224])\n",
      "Epoch 2/10 - Loss: -0.9899\n",
      "Y shape, dataloader: torch.Size([1, 457, 447])\n",
      "Y shape: torch.Size([1, 1, 224, 224])\n",
      "logits shape: torch.Size([1, 3, 224, 224])\n",
      "predictions: torch.Size([1, 3, 224, 224])\n",
      "predictions shape: torch.Size([1, 224, 224]) y shape: torch.Size([1, 1, 224, 224])\n",
      "Epoch 3/10 - Loss: -0.9556\n",
      "Y shape, dataloader: torch.Size([1, 457, 447])\n",
      "Y shape: torch.Size([1, 1, 224, 224])\n",
      "logits shape: torch.Size([1, 3, 224, 224])\n",
      "predictions: torch.Size([1, 3, 224, 224])\n",
      "predictions shape: torch.Size([1, 224, 224]) y shape: torch.Size([1, 1, 224, 224])\n",
      "Epoch 4/10 - Loss: -1.0476\n",
      "Y shape, dataloader: torch.Size([1, 457, 447])\n",
      "Y shape: torch.Size([1, 1, 224, 224])\n",
      "logits shape: torch.Size([1, 3, 224, 224])\n",
      "predictions: torch.Size([1, 3, 224, 224])\n",
      "predictions shape: torch.Size([1, 224, 224]) y shape: torch.Size([1, 1, 224, 224])\n",
      "Epoch 5/10 - Loss: -1.0009\n",
      "Y shape, dataloader: torch.Size([1, 457, 447])\n",
      "Y shape: torch.Size([1, 1, 224, 224])\n",
      "logits shape: torch.Size([1, 3, 224, 224])\n",
      "predictions: torch.Size([1, 3, 224, 224])\n",
      "predictions shape: torch.Size([1, 224, 224]) y shape: torch.Size([1, 1, 224, 224])\n",
      "Epoch 6/10 - Loss: -0.8974\n",
      "Y shape, dataloader: torch.Size([1, 457, 447])\n",
      "Y shape: torch.Size([1, 1, 224, 224])\n",
      "logits shape: torch.Size([1, 3, 224, 224])\n",
      "predictions: torch.Size([1, 3, 224, 224])\n",
      "predictions shape: torch.Size([1, 224, 224]) y shape: torch.Size([1, 1, 224, 224])\n",
      "Epoch 7/10 - Loss: -1.0792\n",
      "Y shape, dataloader: torch.Size([1, 457, 447])\n",
      "Y shape: torch.Size([1, 1, 224, 224])\n",
      "logits shape: torch.Size([1, 3, 224, 224])\n",
      "predictions: torch.Size([1, 3, 224, 224])\n",
      "predictions shape: torch.Size([1, 224, 224]) y shape: torch.Size([1, 1, 224, 224])\n",
      "Epoch 8/10 - Loss: -0.9438\n",
      "Y shape, dataloader: torch.Size([1, 457, 447])\n",
      "Y shape: torch.Size([1, 1, 224, 224])\n",
      "logits shape: torch.Size([1, 3, 224, 224])\n",
      "predictions: torch.Size([1, 3, 224, 224])\n",
      "predictions shape: torch.Size([1, 224, 224]) y shape: torch.Size([1, 1, 224, 224])\n",
      "Epoch 9/10 - Loss: -1.0205\n",
      "Y shape, dataloader: torch.Size([1, 457, 447])\n",
      "Y shape: torch.Size([1, 1, 224, 224])\n",
      "logits shape: torch.Size([1, 3, 224, 224])\n",
      "predictions: torch.Size([1, 3, 224, 224])\n",
      "predictions shape: torch.Size([1, 224, 224]) y shape: torch.Size([1, 1, 224, 224])\n",
      "Epoch 10/10 - Loss: -0.8277\n"
     ]
    }
   ],
   "source": [
    "encoder = TerraMindEncoder()\n",
    "decoder = UNet2D()\n",
    "\n",
    "composed = transforms.Compose([RandomCrop(224)])\n",
    "dataset = BeforeData(before_dir = os.getcwd()+ \"/Images/Before\",\n",
    "                     after_dir = os.getcwd()+ \"/Images/After\",\n",
    "                     label_dir = os.getcwd() + \"/Images/Label\",\n",
    "                    #  input_size = 224\n",
    "                     transform = composed\n",
    "                     )\n",
    "dataloader = DataLoader(dataset)#, batch_size=1, shuffle=True)#, num_workers=0)\n",
    "\n",
    "criterion = DiceLoss()\n",
    "optimizer = optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=1e-3)\n",
    "sigmoid = nn.Sigmoid() # probably can and should delete this? Should be in Encoder\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "# ---- Training Loop ----\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # for sample in dataloader:\n",
    "        # x_before, x_after, y = sample['x_before'].to(device), sample['x_after'].to(device), sample['y'].to(device)\n",
    "\n",
    "    for (x_before, x_after), y in dataloader:\n",
    "        print(\"Y shape:\", y.shape)\n",
    "        x_before, x_after, y = x_before.to(device), x_after.to(device), y.to(device)\n",
    "\n",
    "        # Forward pass (explicit encoder + decoder)\n",
    "        z_before = encoder(x_before)\n",
    "        z_after = encoder(x_after)\n",
    "        z_differenced = [after - before for before, after in zip(z_before, z_after)]\n",
    "\n",
    "        logits = decoder(z_differenced) # reconstruction\n",
    "\n",
    "        print(\"logits shape:\", logits.shape)\n",
    "        predictions = sigmoid(logits) # should this be moved to encoder?\n",
    "        print(\"predictions:\", predictions.shape)\n",
    "        predictions = torch.argmax(predictions, dim=1)\n",
    "        print(\"predictions shape:\", predictions.shape, \"y shape:\", y.shape)\n",
    "\n",
    "        loss = criterion(predictions, y)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.requires_grad = True\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * x_before.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(dataset)\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Loss: {epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "composed = transforms.Compose([RandomCrop(224)])\n",
    "dataset = BeforeData(before_dir = os.getcwd()+ \"/Images/Before\",\n",
    "                     after_dir = os.getcwd()+ \"/Images/After\",\n",
    "                     label_dir = os.getcwd() + \"/Images/Label\",\n",
    "                    #  input_size = 224\n",
    "                     transform = composed\n",
    "                     )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x31dabae40>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataLoader(dataset, batch_size=1, shuffle=True)#, num_workers=0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TerraMind_AgDamage_V1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
